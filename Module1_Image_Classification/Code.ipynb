{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2654 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRISTI\\AppData\\Local\\Temp\\ipykernel_14540\\4022592955.py:48: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train, epochs=30, validation_data=val,verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 68s 3s/step - loss: 1.1418 - accuracy: 0.4857 - val_loss: 3.2620 - val_accuracy: 0.5625\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 55s 3s/step - loss: 0.6958 - accuracy: 0.5934 - val_loss: 1.9021 - val_accuracy: 0.6625\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 52s 2s/step - loss: 0.6385 - accuracy: 0.6673 - val_loss: 2.4015 - val_accuracy: 0.5875\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 51s 2s/step - loss: 0.6928 - accuracy: 0.6213 - val_loss: 5.9074 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.7234 - accuracy: 0.5414 - val_loss: 0.6703 - val_accuracy: 0.6375\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.5978 - accuracy: 0.6620 - val_loss: 0.6384 - val_accuracy: 0.6750\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 51s 2s/step - loss: 0.6100 - accuracy: 0.6843 - val_loss: 1.0415 - val_accuracy: 0.5125\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.6354 - accuracy: 0.6439 - val_loss: 0.5158 - val_accuracy: 0.7375\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.5451 - accuracy: 0.7200 - val_loss: 0.6812 - val_accuracy: 0.7000\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.4764 - accuracy: 0.7717 - val_loss: 0.8911 - val_accuracy: 0.6750\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 53s 3s/step - loss: 0.4371 - accuracy: 0.7935 - val_loss: 0.5217 - val_accuracy: 0.7250\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.3363 - accuracy: 0.8542 - val_loss: 0.6280 - val_accuracy: 0.7125\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.3896 - accuracy: 0.8229 - val_loss: 1.0555 - val_accuracy: 0.6125\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.3291 - accuracy: 0.8576 - val_loss: 1.0121 - val_accuracy: 0.6500\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.2578 - accuracy: 0.9043 - val_loss: 0.4889 - val_accuracy: 0.7625\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 50s 2s/step - loss: 0.2273 - accuracy: 0.9160 - val_loss: 0.4823 - val_accuracy: 0.7750\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 51s 2s/step - loss: 0.1434 - accuracy: 0.9586 - val_loss: 0.6101 - val_accuracy: 0.7000\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 48s 2s/step - loss: 0.0977 - accuracy: 0.9721 - val_loss: 0.7953 - val_accuracy: 0.7125\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0836 - accuracy: 0.9815 - val_loss: 0.5697 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0531 - accuracy: 0.9898 - val_loss: 0.6408 - val_accuracy: 0.7750\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0327 - accuracy: 0.9962 - val_loss: 0.8187 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0264 - accuracy: 0.9955 - val_loss: 0.8390 - val_accuracy: 0.7750\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0211 - accuracy: 0.9977 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 48s 2s/step - loss: 0.0139 - accuracy: 0.9992 - val_loss: 0.7448 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8152 - val_accuracy: 0.7625\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.7883 - val_accuracy: 0.7750\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 49s 2s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.8000\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 51s 2s/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.7004 - val_accuracy: 0.8125\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 56s 3s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.7875\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 52s 3s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "#Import necessary modules for building and training the CNN Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout  #import various types of layers \n",
    "\n",
    "#imports the ImageDataGenerator class from Keras, which is used for loading and preprocessing images.\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "# create an instance of the 'ImageDataGenerator'\n",
    "imagegen = ImageDataGenerator()\n",
    "\n",
    "# loads the training data from the directory\n",
    "train = imagegen.flow_from_directory(r\"C:\\Users\\SHRISTI\\Documents\\GitHub\\Sanket\\Module1_Image_Classification\\train\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "\n",
    "# loads the validation data from the directory\n",
    "val = imagegen.flow_from_directory(r\"C:\\Users\\SHRISTI\\Documents\\GitHub\\Sanket\\Module1_Image_Classification\\valid\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "\n",
    "# build a sequential model and add an inputlayer to it with shape\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "# add a Conv2D layer with 25 filters of size (5, 5), followed by a MaxPool2D layer with a pooling size of (2, 2) and same padding.\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "# add another Conv2D layer with 50 filters of size (5, 5), followed by a MaxPool2D layer with a pooling size of (2, 2) and same padding.\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# add another Conv2D layer with 70 filters of size (3, 3), followed by a MaxPool2D layer with a pooling size of (2, 2) and same padding.\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# adds the output layer with 2 units/neurons and a softmax activation function\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "# compile model \n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# fit on data for 30 epochs\n",
    "model.fit_generator(train, epochs=30, validation_data=val,verbose=1)\n",
    "\n",
    "#save the model\n",
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
